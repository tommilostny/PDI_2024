> Configure project :
The application will run with add-opens JVM args to fix Spark on JDK 17.

> Task :run
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
24/11/24 16:51:38 INFO SparkContext: Running Spark version 3.5.1
24/11/24 16:51:38 INFO SparkContext: OS info Windows 11, 10.0, amd64
24/11/24 16:51:38 INFO SparkContext: Java version 21.0.5
24/11/24 16:51:38 INFO ResourceUtils: ==============================================================
24/11/24 16:51:38 INFO ResourceUtils: No custom resources configured for spark.driver.
24/11/24 16:51:38 INFO ResourceUtils: ==============================================================
24/11/24 16:51:38 INFO SparkContext: Submitted application: PeopleInYear$
24/11/24 16:51:38 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/11/24 16:51:38 INFO ResourceProfile: Limiting resource is cpu
24/11/24 16:51:38 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/11/24 16:51:38 INFO SecurityManager: Changing view acls to: tommi
24/11/24 16:51:38 INFO SecurityManager: Changing modify acls to: tommi
24/11/24 16:51:38 INFO SecurityManager: Changing view acls groups to:
24/11/24 16:51:38 INFO SecurityManager: Changing modify acls groups to:
24/11/24 16:51:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: tommi; groups with view permissions: EMPTY; users with modify permissions: tommi; groups with modify permissions: EMPTY
24/11/24 16:51:38 INFO Utils: Successfully started service 'sparkDriver' on port 51375.
24/11/24 16:51:38 INFO SparkEnv: Registering MapOutputTracker
24/11/24 16:51:39 INFO SparkEnv: Registering BlockManagerMaster
24/11/24 16:51:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/11/24 16:51:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/11/24 16:51:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/11/24 16:51:39 INFO DiskBlockManager: Created local directory at C:\Users\tommi\AppData\Local\Temp\blockmgr-7acc7a6f-bf8a-4132-890c-f4e82d6c6e87
24/11/24 16:51:39 INFO MemoryStore: MemoryStore started with capacity 2.1 GiB
24/11/24 16:51:39 INFO SparkEnv: Registering OutputCommitCoordinator
24/11/24 16:51:39 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/11/24 16:51:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/11/24 16:51:39 INFO Executor: Starting executor ID driver on host host.docker.internal
24/11/24 16:51:39 INFO Executor: OS info Windows 11, 10.0, amd64
24/11/24 16:51:39 INFO Executor: Java version 21.0.5
24/11/24 16:51:39 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/11/24 16:51:39 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@6192a5d5 for default.
24/11/24 16:51:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51376.
24/11/24 16:51:39 INFO NettyBlockTransferService: Server created on host.docker.internal:51376
24/11/24 16:51:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/11/24 16:51:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, host.docker.internal, 51376, None)
24/11/24 16:51:39 INFO BlockManagerMasterEndpoint: Registering block manager host.docker.internal:51376 with 2.1 GiB RAM, BlockManagerId(driver, host.docker.internal, 51376, None)
24/11/24 16:51:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, host.docker.internal, 51376, None)
24/11/24 16:51:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 51376, None)
24/11/24 16:51:39 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
24/11/24 16:51:39 INFO SharedState: Warehouse path is 'file:/C:/Users/tommi/projects/PDI/download-lab-spark-peopleinyear/peopleinyear-spark/spark-warehouse'.
24/11/24 16:51:40 INFO InMemoryFileIndex: It took 32 ms to list leaf files for 1 paths.
24/11/24 16:51:40 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
24/11/24 16:51:41 INFO FileSourceStrategy: Pushed Filters:
24/11/24 16:51:41 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
24/11/24 16:51:42 INFO CodeGenerator: Code generated in 152.8462 ms
24/11/24 16:51:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 198.8 KiB, free 2.1 GiB)
24/11/24 16:51:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.1 GiB)
24/11/24 16:51:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on host.docker.internal:51376 (size: 34.2 KiB, free: 2.1 GiB)
24/11/24 16:51:42 INFO SparkContext: Created broadcast 0 from load at PeopleInYear.scala:37
24/11/24 16:51:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/11/24 16:51:42 INFO SparkContext: Starting job: load at PeopleInYear.scala:37
24/11/24 16:51:42 INFO DAGScheduler: Got job 0 (load at PeopleInYear.scala:37) with 1 output partitions
24/11/24 16:51:42 INFO DAGScheduler: Final stage: ResultStage 0 (load at PeopleInYear.scala:37)
24/11/24 16:51:42 INFO DAGScheduler: Parents of final stage: List()
24/11/24 16:51:42 INFO DAGScheduler: Missing parents: List()
24/11/24 16:51:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at PeopleInYear.scala:37), which has no missing parents
24/11/24 16:51:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 2.1 GiB
24/11/24 16:51:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 2.1 GiB)
24/11/24 16:51:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on host.docker.internal:51376 (size: 6.4 KiB, free: 2.1 GiB)
24/11/24 16:51:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
24/11/24 16:51:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at PeopleInYear.scala:37) (first 15 tasks are for partitions Vector(0))
24/11/24 16:51:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/11/24 16:51:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 8293 bytes)
24/11/24 16:51:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/11/24 16:51:42 INFO CodeGenerator: Code generated in 8.6166 ms
24/11/24 16:51:42 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 0-4194304, partition values: [empty row]
24/11/24 16:51:42 INFO CodeGenerator: Code generated in 9.3633 ms
24/11/24 16:51:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2008 bytes result sent to driver
24/11/24 16:51:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 181 ms on host.docker.internal (executor driver) (1/1)
24/11/24 16:51:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
24/11/24 16:51:42 INFO DAGScheduler: ResultStage 0 (load at PeopleInYear.scala:37) finished in 0,268 s
24/11/24 16:51:42 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/11/24 16:51:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/11/24 16:51:42 INFO DAGScheduler: Job 0 finished: load at PeopleInYear.scala:37, took 0,302287 s
24/11/24 16:51:42 INFO CodeGenerator: Code generated in 5.6441 ms
24/11/24 16:51:42 INFO FileSourceStrategy: Pushed Filters:
24/11/24 16:51:42 INFO FileSourceStrategy: Post-Scan Filters:
24/11/24 16:51:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 198.8 KiB, free 2.1 GiB)
24/11/24 16:51:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.1 GiB)
24/11/24 16:51:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on host.docker.internal:51376 (size: 34.2 KiB, free: 2.1 GiB)
24/11/24 16:51:42 INFO SparkContext: Created broadcast 2 from load at PeopleInYear.scala:37
24/11/24 16:51:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/11/24 16:51:42 INFO SparkContext: Starting job: load at PeopleInYear.scala:37
24/11/24 16:51:42 INFO DAGScheduler: Got job 1 (load at PeopleInYear.scala:37) with 5 output partitions
24/11/24 16:51:42 INFO DAGScheduler: Final stage: ResultStage 1 (load at PeopleInYear.scala:37)
24/11/24 16:51:42 INFO DAGScheduler: Parents of final stage: List()
24/11/24 16:51:42 INFO DAGScheduler: Missing parents: List()
24/11/24 16:51:42 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at PeopleInYear.scala:37), which has no missing parents
24/11/24 16:51:42 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 28.6 KiB, free 2.1 GiB)
24/11/24 16:51:42 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.1 KiB, free 2.1 GiB)
24/11/24 16:51:42 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on host.docker.internal:51376 (size: 13.1 KiB, free: 2.1 GiB)
24/11/24 16:51:42 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
24/11/24 16:51:42 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at PeopleInYear.scala:37) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
24/11/24 16:51:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks resource profile 0
24/11/24 16:51:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 8293 bytes)
24/11/24 16:51:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (host.docker.internal, executor driver, partition 1, PROCESS_LOCAL, 8293 bytes)
24/11/24 16:51:42 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (host.docker.internal, executor driver, partition 2, PROCESS_LOCAL, 8293 bytes)
24/11/24 16:51:42 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (host.docker.internal, executor driver, partition 3, PROCESS_LOCAL, 8293 bytes)
24/11/24 16:51:42 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (host.docker.internal, executor driver, partition 4, PROCESS_LOCAL, 8293 bytes)
24/11/24 16:51:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/11/24 16:51:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
24/11/24 16:51:42 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
24/11/24 16:51:42 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
24/11/24 16:51:42 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)
24/11/24 16:51:43 INFO CodeGenerator: Code generated in 4.1707 ms
24/11/24 16:51:43 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 4194304-8388608, partition values: [empty row]
24/11/24 16:51:43 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 0-4194304, partition values: [empty row]
24/11/24 16:51:43 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 8388608-12582912, partition values: [empty row]
24/11/24 16:51:43 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 12582912-16777216, partition values: [empty row]
24/11/24 16:51:43 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 16777216-17178174, partition values: [empty row]
24/11/24 16:51:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on host.docker.internal:51376 in memory (size: 6.4 KiB, free: 2.1 GiB)
24/11/24 16:51:43 INFO BlockManagerInfo: Removed broadcast_0_piece0 on host.docker.internal:51376 in memory (size: 34.2 KiB, free: 2.1 GiB)
24/11/24 16:51:43 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 2194 bytes result sent to driver
24/11/24 16:51:43 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 278 ms on host.docker.internal (executor driver) (1/5)
24/11/24 16:51:43 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2151 bytes result sent to driver
24/11/24 16:51:43 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2151 bytes result sent to driver
24/11/24 16:51:43 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2151 bytes result sent to driver
24/11/24 16:51:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2151 bytes result sent to driver
24/11/24 16:51:43 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 423 ms on host.docker.internal (executor driver) (2/5)
24/11/24 16:51:43 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 423 ms on host.docker.internal (executor driver) (3/5)
24/11/24 16:51:43 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 423 ms on host.docker.internal (executor driver) (4/5)
24/11/24 16:51:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 424 ms on host.docker.internal (executor driver) (5/5)
24/11/24 16:51:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
24/11/24 16:51:43 INFO DAGScheduler: ResultStage 1 (load at PeopleInYear.scala:37) finished in 0,452 s
24/11/24 16:51:43 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/11/24 16:51:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/11/24 16:51:43 INFO DAGScheduler: Job 1 finished: load at PeopleInYear.scala:37, took 0,456689 s
24/11/24 16:51:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(JM├ëNO),StringStartsWith(JM├ëNO,MA)
24/11/24 16:51:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(JM├ëNO#17),StartsWith(JM├ëNO#17, MA)
24/11/24 16:51:43 INFO CodeGenerator: Code generated in 15.6375 ms
24/11/24 16:51:43 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 198.7 KiB, free 2.1 GiB)
24/11/24 16:51:43 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.1 GiB)
24/11/24 16:51:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on host.docker.internal:51376 (size: 34.2 KiB, free: 2.1 GiB)
24/11/24 16:51:43 INFO SparkContext: Created broadcast 4 from save at PeopleInYear.scala:49
24/11/24 16:51:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/11/24 16:51:43 INFO DAGScheduler: Registering RDD 13 (save at PeopleInYear.scala:49) as input to shuffle 0
24/11/24 16:51:43 INFO DAGScheduler: Got map stage job 2 (save at PeopleInYear.scala:49) with 5 output partitions
24/11/24 16:51:43 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (save at PeopleInYear.scala:49)
24/11/24 16:51:43 INFO DAGScheduler: Parents of final stage: List()
24/11/24 16:51:43 INFO DAGScheduler: Missing parents: List()
24/11/24 16:51:43 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at save at PeopleInYear.scala:49), which has no missing parents
24/11/24 16:51:43 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 24.8 KiB, free 2.1 GiB
24/11/24 16:51:43 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 2.1 GiB)
24/11/24 16:51:43 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on host.docker.internal:51376 (size: 11.2 KiB, free: 2.1 GiB)
24/11/24 16:51:43 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
24/11/24 16:51:43 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at save at PeopleInYear.scala:49) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
24/11/24 16:51:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks resource profile 0
24/11/24 16:51:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 6) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)
24/11/24 16:51:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 7) (host.docker.internal, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)
24/11/24 16:51:43 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 8) (host.docker.internal, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)
24/11/24 16:51:43 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 9) (host.docker.internal, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)
24/11/24 16:51:43 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 10) (host.docker.internal, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)
24/11/24 16:51:43 INFO Executor: Running task 4.0 in stage 2.0 (TID 10)
24/11/24 16:51:43 INFO Executor: Running task 2.0 in stage 2.0 (TID 8)
24/11/24 16:51:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 6)
24/11/24 16:51:43 INFO Executor: Running task 3.0 in stage 2.0 (TID 9)
24/11/24 16:51:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 7)
24/11/24 16:51:43 INFO CodeGenerator: Code generated in 10.6243 ms
24/11/24 16:51:43 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 12582912-16777216, partition values: [empty row]
24/11/24 16:51:43 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 16777216-17178174, partition values: [empty row]
24/11/24 16:51:43 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 4194304-8388608, partition values: [empty row]
24/11/24 16:51:43 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 8388608-12582912, partition values: [empty row]
24/11/24 16:51:43 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 0-4194304, partition values: [empty row]
24/11/24 16:51:43 INFO CodeGenerator: Code generated in 4.8455 ms
24/11/24 16:51:43 INFO CodeGenerator: Code generated in 5.071599 ms
24/11/24 16:51:44 INFO Executor: Finished task 4.0 in stage 2.0 (TID 10). 1949 bytes result sent to driver
24/11/24 16:51:44 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 10) in 237 ms on host.docker.internal (executor driver) (1/5)
24/11/24 16:51:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 6). 1906 bytes result sent to driver
24/11/24 16:51:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 6) in 252 ms on host.docker.internal (executor driver) (2/5)
24/11/24 16:51:44 INFO Executor: Finished task 3.0 in stage 2.0 (TID 9). 1906 bytes result sent to driver
24/11/24 16:51:44 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 9) in 252 ms on host.docker.internal (executor driver) (3/5)
24/11/24 16:51:44 INFO Executor: Finished task 1.0 in stage 2.0 (TID 7). 1906 bytes result sent to driver
24/11/24 16:51:44 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 7) in 253 ms on host.docker.internal (executor driver) (4/5)
24/11/24 16:51:44 INFO Executor: Finished task 2.0 in stage 2.0 (TID 8). 2035 bytes result sent to driver
24/11/24 16:51:44 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 8) in 260 ms on host.docker.internal (executor driver) (5/5)
24/11/24 16:51:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
24/11/24 16:51:44 INFO DAGScheduler: ShuffleMapStage 2 (save at PeopleInYear.scala:49) finished in 0,279 s
24/11/24 16:51:44 INFO DAGScheduler: looking for newly runnable stages
24/11/24 16:51:44 INFO DAGScheduler: running: Set()
24/11/24 16:51:44 INFO DAGScheduler: waiting: Set()
24/11/24 16:51:44 INFO DAGScheduler: failed: Set()
24/11/24 16:51:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/11/24 16:51:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/11/24 16:51:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
24/11/24 16:51:44 INFO CodeGenerator: Code generated in 8.7943 ms
24/11/24 16:51:44 INFO SparkContext: Starting job: save at PeopleInYear.scala:49
24/11/24 16:51:44 INFO DAGScheduler: Got job 3 (save at PeopleInYear.scala:49) with 1 output partitions
24/11/24 16:51:44 INFO DAGScheduler: Final stage: ResultStage 4 (save at PeopleInYear.scala:49)
24/11/24 16:51:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
24/11/24 16:51:44 INFO DAGScheduler: Missing parents: List()
24/11/24 16:51:44 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at save at PeopleInYear.scala:49), which has no missing parents
24/11/24 16:51:44 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 215.8 KiB, free 2.1 GiB)
24/11/24 16:51:44 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 77.7 KiB, free 2.1 GiB)
24/11/24 16:51:44 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on host.docker.internal:51376 (size: 77.7 KiB, free: 2.1 GiB)
24/11/24 16:51:44 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
24/11/24 16:51:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at save at PeopleInYear.scala:49) (first 15 tasks are for partitions Vector(0))
24/11/24 16:51:44 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/11/24 16:51:44 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 11) (host.docker.internal, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
24/11/24 16:51:44 INFO Executor: Running task 0.0 in stage 4.0 (TID 11)
24/11/24 16:51:44 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/11/24 16:51:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
24/11/24 16:51:44 INFO CodeGenerator: Code generated in 6.4277 ms
24/11/24 16:51:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/11/24 16:51:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/11/24 16:51:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
24/11/24 16:51:44 INFO FileOutputCommitter: Saved output of task 'attempt_202411241651443623038783803148153_0004_m_000000_11' to file:/C:/Users/tommi/projects/PDI/download-lab-spark-peopleinyear/peopleinyear-spark/peopleinyear.spark_output/as-dataframe/_temporary/0/task_202411241651443623038783803148153_0004_m_000000
24/11/24 16:51:44 INFO SparkHadoopMapRedUtil: attempt_202411241651443623038783803148153_0004_m_000000_11: Committed. Elapsed time: 2 ms.
24/11/24 16:51:44 INFO Executor: Finished task 0.0 in stage 4.0 (TID 11). 4974 bytes result sent to driver
24/11/24 16:51:44 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 11) in 119 ms on host.docker.internal (executor driver) (1/1)
24/11/24 16:51:44 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
24/11/24 16:51:44 INFO DAGScheduler: ResultStage 4 (save at PeopleInYear.scala:49) finished in 0,146 s
24/11/24 16:51:44 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/11/24 16:51:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/11/24 16:51:44 INFO DAGScheduler: Job 3 finished: save at PeopleInYear.scala:49, took 0,152754 s
24/11/24 16:51:44 INFO FileFormatWriter: Start to commit write Job 1c341363-0831-434a-960e-b2daf7c23ed3.
24/11/24 16:51:44 INFO FileFormatWriter: Write Job 1c341363-0831-434a-960e-b2daf7c23ed3 committed. Elapsed time: 14 ms.
24/11/24 16:51:44 INFO FileFormatWriter: Finished processing stats for write job 1c341363-0831-434a-960e-b2daf7c23ed3.
24/11/24 16:51:44 INFO FileSourceStrategy: Pushed Filters:
24/11/24 16:51:44 INFO FileSourceStrategy: Post-Scan Filters:
24/11/24 16:51:44 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 198.7 KiB, free 2.1 GiB)
24/11/24 16:51:44 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.1 GiB)
24/11/24 16:51:44 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on host.docker.internal:51376 (size: 34.2 KiB, free: 2.1 GiB)
24/11/24 16:51:44 INFO SparkContext: Created broadcast 7 from rdd at PeopleInYear.scala:53
24/11/24 16:51:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/11/24 16:51:44 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
24/11/24 16:51:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
24/11/24 16:51:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/11/24 16:51:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/11/24 16:51:44 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
24/11/24 16:51:44 INFO DAGScheduler: Registering RDD 24 (filter at PeopleInYear.scala:58) as input to shuffle 1
24/11/24 16:51:44 INFO DAGScheduler: Got job 4 (runJob at SparkHadoopWriter.scala:83) with 5 output partitions
24/11/24 16:51:44 INFO DAGScheduler: Final stage: ResultStage 6 (runJob at SparkHadoopWriter.scala:83)
24/11/24 16:51:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
24/11/24 16:51:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
24/11/24 16:51:44 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at filter at PeopleInYear.scala:58), which has no missing parents
24/11/24 16:51:44 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 63.6 KiB, free 2.1 GiB)
24/11/24 16:51:44 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.4 KiB, free 2.1 GiB)
24/11/24 16:51:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on host.docker.internal:51376 (size: 21.4 KiB, free: 2.1 GiB)
24/11/24 16:51:44 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
24/11/24 16:51:44 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at filter at PeopleInYear.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
24/11/24 16:51:44 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks resource profile 0
24/11/24 16:51:44 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 12) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 8282 bytes)
24/11/24 16:51:44 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 13) (host.docker.internal, executor driver, partition 1, PROCESS_LOCAL, 8282 bytes)
24/11/24 16:51:44 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 14) (host.docker.internal, executor driver, partition 2, PROCESS_LOCAL, 8282 bytes)
24/11/24 16:51:44 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 15) (host.docker.internal, executor driver, partition 3, PROCESS_LOCAL, 8282 bytes)
24/11/24 16:51:44 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 16) (host.docker.internal, executor driver, partition 4, PROCESS_LOCAL, 8282 bytes)
24/11/24 16:51:44 INFO Executor: Running task 1.0 in stage 5.0 (TID 13)
24/11/24 16:51:44 INFO Executor: Running task 0.0 in stage 5.0 (TID 12)
24/11/24 16:51:44 INFO Executor: Running task 4.0 in stage 5.0 (TID 16)
24/11/24 16:51:44 INFO Executor: Running task 3.0 in stage 5.0 (TID 15)
24/11/24 16:51:44 INFO Executor: Running task 2.0 in stage 5.0 (TID 14)
24/11/24 16:51:44 INFO CodeGenerator: Code generated in 51.9062 ms
24/11/24 16:51:44 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 0-4194304, partition values: [empty row]
24/11/24 16:51:44 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 16777216-17178174, partition values: [empty row]
24/11/24 16:51:44 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 4194304-8388608, partition values: [empty row]
24/11/24 16:51:44 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 8388608-12582912, partition values: [empty row]
24/11/24 16:51:44 INFO FileScanRDD: Reading File path: file:///C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv, range: 12582912-16777216, partition values: [empty row]
24/11/24 16:51:44 INFO CodeGenerator: Code generated in 26.5492 ms
24/11/24 16:51:44 INFO BlockManagerInfo: Removed broadcast_6_piece0 on host.docker.internal:51376 in memory (size: 77.7 KiB, free: 2.1 GiB)
24/11/24 16:51:44 INFO BlockManagerInfo: Removed broadcast_4_piece0 on host.docker.internal:51376 in memory (size: 34.2 KiB, free: 2.1 GiB)
24/11/24 16:51:44 INFO Executor: Finished task 4.0 in stage 5.0 (TID 16). 1688 bytes result sent to driver
24/11/24 16:51:44 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 16) in 330 ms on host.docker.internal (executor driver) (1/5)
24/11/24 16:51:44 INFO BlockManagerInfo: Removed broadcast_5_piece0 on host.docker.internal:51376 in memory (size: 11.2 KiB, free: 2.1 GiB)
24/11/24 16:51:45 INFO Executor: Finished task 0.0 in stage 5.0 (TID 12). 1688 bytes result sent to driver
24/11/24 16:51:45 INFO Executor: Finished task 1.0 in stage 5.0 (TID 13). 1688 bytes result sent to driver
24/11/24 16:51:45 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 12) in 480 ms on host.docker.internal (executor driver) (2/5)
24/11/24 16:51:45 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 13) in 480 ms on host.docker.internal (executor driver) (3/5)
24/11/24 16:51:45 INFO Executor: Finished task 3.0 in stage 5.0 (TID 15). 1731 bytes result sent to driver
24/11/24 16:51:45 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 15) in 483 ms on host.docker.internal (executor driver) (4/5)
24/11/24 16:51:45 INFO Executor: Finished task 2.0 in stage 5.0 (TID 14). 1774 bytes result sent to driver
24/11/24 16:51:45 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 14) in 577 ms on host.docker.internal (executor driver) (5/5)
24/11/24 16:51:45 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
24/11/24 16:51:45 INFO DAGScheduler: ShuffleMapStage 5 (filter at PeopleInYear.scala:58) finished in 0,593 s
24/11/24 16:51:45 INFO DAGScheduler: looking for newly runnable stages
24/11/24 16:51:45 INFO DAGScheduler: running: Set()
24/11/24 16:51:45 INFO DAGScheduler: waiting: Set(ResultStage 6)
24/11/24 16:51:45 INFO DAGScheduler: failed: Set()
24/11/24 16:51:45 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at saveAsTextFile at PeopleInYear.scala:64), which has no missing parents
24/11/24 16:51:45 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 103.9 KiB, free 2.1 GiB)
24/11/24 16:51:45 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 37.9 KiB, free 2.1 GiB)
24/11/24 16:51:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on host.docker.internal:51376 (size: 37.9 KiB, free: 2.1 GiB)
24/11/24 16:51:45 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
24/11/24 16:51:45 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at saveAsTextFile at PeopleInYear.scala:64) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
24/11/24 16:51:45 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks resource profile 0
24/11/24 16:51:45 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 17) (host.docker.internal, executor driver, partition 1, NODE_LOCAL, 7433 bytes)
24/11/24 16:51:45 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 18) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7433 bytes)
24/11/24 16:51:45 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 19) (host.docker.internal, executor driver, partition 2, PROCESS_LOCAL, 7433 bytes)
24/11/24 16:51:45 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 20) (host.docker.internal, executor driver, partition 3, PROCESS_LOCAL, 7433 bytes)
24/11/24 16:51:45 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 21) (host.docker.internal, executor driver, partition 4, PROCESS_LOCAL, 7433 bytes)
24/11/24 16:51:45 INFO Executor: Running task 0.0 in stage 6.0 (TID 18)
24/11/24 16:51:45 INFO Executor: Running task 4.0 in stage 6.0 (TID 21)
24/11/24 16:51:45 INFO Executor: Running task 2.0 in stage 6.0 (TID 19)
24/11/24 16:51:45 INFO Executor: Running task 3.0 in stage 6.0 (TID 20)
24/11/24 16:51:45 INFO Executor: Running task 1.0 in stage 6.0 (TID 17)
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/11/24 16:51:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
24/11/24 16:51:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
24/11/24 16:51:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
24/11/24 16:51:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
24/11/24 16:51:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
24/11/24 16:51:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/11/24 16:51:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/11/24 16:51:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/11/24 16:51:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/11/24 16:51:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/11/24 16:51:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/11/24 16:51:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/11/24 16:51:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/11/24 16:51:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/11/24 16:51:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/11/24 16:51:45 INFO FileOutputCommitter: Saved output of task 'attempt_202411241651444870581191744900891_0026_m_000003_0' to file:/C:/Users/tommi/projects/PDI/download-lab-spark-peopleinyear/peopleinyear-spark/peopleinyear.spark_output/as-rdd-from-dataframe/_temporary/0/task_202411241651444870581191744900891_0026_m_000003
24/11/24 16:51:45 INFO FileOutputCommitter: Saved output of task 'attempt_202411241651444870581191744900891_0026_m_000001_0' to file:/C:/Users/tommi/projects/PDI/download-lab-spark-peopleinyear/peopleinyear-spark/peopleinyear.spark_output/as-rdd-from-dataframe/_temporary/0/task_202411241651444870581191744900891_0026_m_000001
24/11/24 16:51:45 INFO SparkHadoopMapRedUtil: attempt_202411241651444870581191744900891_0026_m_000003_0: Committed. Elapsed time: 7 ms.
24/11/24 16:51:45 INFO SparkHadoopMapRedUtil: attempt_202411241651444870581191744900891_0026_m_000001_0: Committed. Elapsed time: 7 ms.
24/11/24 16:51:45 INFO Executor: Finished task 1.0 in stage 6.0 (TID 17). 1944 bytes result sent to driver
24/11/24 16:51:45 INFO Executor: Finished task 3.0 in stage 6.0 (TID 20). 1858 bytes result sent to driver
24/11/24 16:51:45 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 17) in 73 ms on host.docker.internal (executor driver) (1/5)
24/11/24 16:51:45 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 20) in 72 ms on host.docker.internal (executor driver) (2/5)
24/11/24 16:51:45 INFO FileOutputCommitter: Saved output of task 'attempt_202411241651444870581191744900891_0026_m_000000_0' to file:/C:/Users/tommi/projects/PDI/download-lab-spark-peopleinyear/peopleinyear-spark/peopleinyear.spark_output/as-rdd-from-dataframe/_temporary/0/task_202411241651444870581191744900891_0026_m_000000
24/11/24 16:51:45 INFO FileOutputCommitter: Saved output of task 'attempt_202411241651444870581191744900891_0026_m_000004_0' to file:/C:/Users/tommi/projects/PDI/download-lab-spark-peopleinyear/peopleinyear-spark/peopleinyear.spark_output/as-rdd-from-dataframe/_temporary/0/task_202411241651444870581191744900891_0026_m_000004
24/11/24 16:51:45 INFO SparkHadoopMapRedUtil: attempt_202411241651444870581191744900891_0026_m_000000_0: Committed. Elapsed time: 18 ms.
24/11/24 16:51:45 INFO SparkHadoopMapRedUtil: attempt_202411241651444870581191744900891_0026_m_000004_0: Committed. Elapsed time: 18 ms.
24/11/24 16:51:45 INFO Executor: Finished task 4.0 in stage 6.0 (TID 21). 1858 bytes result sent to driver
24/11/24 16:51:45 INFO Executor: Finished task 0.0 in stage 6.0 (TID 18). 1858 bytes result sent to driver
24/11/24 16:51:45 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 21) in 81 ms on host.docker.internal (executor driver) (3/5)
24/11/24 16:51:45 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 18) in 82 ms on host.docker.internal (executor driver) (4/5)
24/11/24 16:51:45 INFO FileOutputCommitter: Saved output of task 'attempt_202411241651444870581191744900891_0026_m_000002_0' to file:/C:/Users/tommi/projects/PDI/download-lab-spark-peopleinyear/peopleinyear-spark/peopleinyear.spark_output/as-rdd-from-dataframe/_temporary/0/task_202411241651444870581191744900891_0026_m_000002
24/11/24 16:51:45 INFO SparkHadoopMapRedUtil: attempt_202411241651444870581191744900891_0026_m_000002_0: Committed. Elapsed time: 29 ms.
24/11/24 16:51:45 INFO Executor: Finished task 2.0 in stage 6.0 (TID 19). 1858 bytes result sent to driver
24/11/24 16:51:45 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 19) in 95 ms on host.docker.internal (executor driver) (5/5)
24/11/24 16:51:45 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
24/11/24 16:51:45 INFO DAGScheduler: ResultStage 6 (runJob at SparkHadoopWriter.scala:83) finished in 0,107 s
24/11/24 16:51:45 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/11/24 16:51:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
24/11/24 16:51:45 INFO DAGScheduler: Job 4 finished: runJob at SparkHadoopWriter.scala:83, took 0,828429 s
24/11/24 16:51:45 INFO SparkHadoopWriter: Start to commit write Job job_202411241651444870581191744900891_0026.
24/11/24 16:51:45 INFO SparkHadoopWriter: Write Job job_202411241651444870581191744900891_0026 committed. Elapsed time: 16 ms.
24/11/24 16:51:45 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 221.7 KiB, free 2.1 GiB)
24/11/24 16:51:45 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 2.1 GiB)
24/11/24 16:51:45 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on host.docker.internal:51376 (size: 32.7 KiB, free: 2.1 GiB)
24/11/24 16:51:45 INFO SparkContext: Created broadcast 10 from textFile at PeopleInYear.scala:68
24/11/24 16:51:45 INFO FileInputFormat: Total input files to process : 1
24/11/24 16:51:45 INFO SparkContext: Starting job: first at PeopleInYear.scala:70
24/11/24 16:51:45 INFO DAGScheduler: Got job 5 (first at PeopleInYear.scala:70) with 1 output partitions
24/11/24 16:51:45 INFO DAGScheduler: Final stage: ResultStage 7 (first at PeopleInYear.scala:70)
24/11/24 16:51:45 INFO DAGScheduler: Parents of final stage: List()
24/11/24 16:51:45 INFO DAGScheduler: Missing parents: List()
24/11/24 16:51:45 INFO DAGScheduler: Submitting ResultStage 7 (..\..\download-cetnost-jmena-dnar-2016\cetnost-jmena-dnar-2016\cetnost-jmena-dnar.csv MapPartitionsRDD[28] at textFile at PeopleInYear.scala:68), which has no missing parents
24/11/24 16:51:45 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 5.0 KiB, free 2.1 GiB)
24/11/24 16:51:45 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 2.1 GiB)
24/11/24 16:51:45 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on host.docker.internal:51376 (size: 2.8 KiB, free: 2.1 GiB)
24/11/24 16:51:45 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
24/11/24 16:51:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (..\..\download-cetnost-jmena-dnar-2016\cetnost-jmena-dnar-2016\cetnost-jmena-dnar.csv MapPartitionsRDD[28] at textFile at PeopleInYear.scala:68) (first 15 tasks are for partitions Vector(0))
24/11/24 16:51:45 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
24/11/24 16:51:45 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 22) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7744 bytes)
24/11/24 16:51:45 INFO Executor: Running task 0.0 in stage 7.0 (TID 22)
24/11/24 16:51:45 INFO HadoopRDD: Input split: file:/C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv:0+8589087
24/11/24 16:51:45 INFO Executor: Finished task 0.0 in stage 7.0 (TID 22). 1446 bytes result sent to driver
24/11/24 16:51:45 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 22) in 18 ms on host.docker.internal (executor driver) (1/1)
24/11/24 16:51:45 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
24/11/24 16:51:45 INFO DAGScheduler: ResultStage 7 (first at PeopleInYear.scala:70) finished in 0,023 s
24/11/24 16:51:45 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/11/24 16:51:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
24/11/24 16:51:45 INFO DAGScheduler: Job 5 finished: first at PeopleInYear.scala:70, took 0,024132 s
24/11/24 16:51:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
24/11/24 16:51:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/11/24 16:51:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/11/24 16:51:45 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
24/11/24 16:51:45 INFO DAGScheduler: Registering RDD 32 (filter at PeopleInYear.scala:81) as input to shuffle 2
24/11/24 16:51:45 INFO DAGScheduler: Got job 6 (runJob at SparkHadoopWriter.scala:83) with 2 output partitions
24/11/24 16:51:45 INFO DAGScheduler: Final stage: ResultStage 9 (runJob at SparkHadoopWriter.scala:83)
24/11/24 16:51:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
24/11/24 16:51:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
24/11/24 16:51:45 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[32] at filter at PeopleInYear.scala:81), which has no missing parents
24/11/24 16:51:45 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KiB, free 2.1 GiB)
24/11/24 16:51:45 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 2.1 GiB)
24/11/24 16:51:45 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on host.docker.internal:51376 (size: 4.7 KiB, free: 2.1 GiB)
24/11/24 16:51:45 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
24/11/24 16:51:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[32] at filter at PeopleInYear.scala:81) (first 15 tasks are for partitions Vector(0, 1))
24/11/24 16:51:45 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks resource profile 0
24/11/24 16:51:45 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 23) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7733 bytes)
24/11/24 16:51:45 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 24) (host.docker.internal, executor driver, partition 1, PROCESS_LOCAL, 7733 bytes)
24/11/24 16:51:45 INFO Executor: Running task 0.0 in stage 8.0 (TID 23)
24/11/24 16:51:45 INFO Executor: Running task 1.0 in stage 8.0 (TID 24)
24/11/24 16:51:45 INFO HadoopRDD: Input split: file:/C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv:0+8589087
24/11/24 16:51:45 INFO HadoopRDD: Input split: file:/C:/Users/tommi/projects/PDI/download-cetnost-jmena-dnar-2016/cetnost-jmena-dnar-2016/cetnost-jmena-dnar.csv:8589087+8589087
24/11/24 16:51:45 INFO Executor: Finished task 0.0 in stage 8.0 (TID 23). 1096 bytes result sent to driver
24/11/24 16:51:45 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 23) in 47 ms on host.docker.internal (executor driver) (1/2)
24/11/24 16:51:45 INFO Executor: Finished task 1.0 in stage 8.0 (TID 24). 1268 bytes result sent to driver
24/11/24 16:51:45 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 24) in 163 ms on host.docker.internal (executor driver) (2/2)
24/11/24 16:51:45 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
24/11/24 16:51:45 INFO DAGScheduler: ShuffleMapStage 8 (filter at PeopleInYear.scala:81) finished in 0,167 s
24/11/24 16:51:45 INFO DAGScheduler: looking for newly runnable stages
24/11/24 16:51:45 INFO DAGScheduler: running: Set()
24/11/24 16:51:45 INFO DAGScheduler: waiting: Set(ResultStage 9)
24/11/24 16:51:45 INFO DAGScheduler: failed: Set()
24/11/24 16:51:45 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[34] at saveAsTextFile at PeopleInYear.scala:87), which has no missing parents
24/11/24 16:51:45 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 103.8 KiB, free 2.1 GiB)
24/11/24 16:51:45 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 37.9 KiB, free 2.1 GiB)
24/11/24 16:51:45 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on host.docker.internal:51376 (size: 37.9 KiB, free: 2.1 GiB)
24/11/24 16:51:45 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
24/11/24 16:51:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[34] at saveAsTextFile at PeopleInYear.scala:87) (first 15 tasks are for partitions Vector(0, 1))
24/11/24 16:51:45 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks resource profile 0
24/11/24 16:51:45 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 25) (host.docker.internal, executor driver, partition 1, NODE_LOCAL, 7433 bytes)
24/11/24 16:51:45 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 26) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7433 bytes)
24/11/24 16:51:45 INFO Executor: Running task 1.0 in stage 9.0 (TID 25)
24/11/24 16:51:45 INFO Executor: Running task 0.0 in stage 9.0 (TID 26)
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Getting 1 (54.0 B) non-empty blocks including 1 (54.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/11/24 16:51:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/11/24 16:51:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
24/11/24 16:51:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/11/24 16:51:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/11/24 16:51:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
24/11/24 16:51:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/11/24 16:51:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/11/24 16:51:45 INFO FileOutputCommitter: Saved output of task 'attempt_202411241651456558149428303465042_0034_m_000000_0' to file:/C:/Users/tommi/projects/PDI/download-lab-spark-peopleinyear/peopleinyear-spark/peopleinyear.spark_output/as-rdd/_temporary/0/task_202411241651456558149428303465042_0034_m_000000
24/11/24 16:51:45 INFO SparkHadoopMapRedUtil: attempt_202411241651456558149428303465042_0034_m_000000_0: Committed. Elapsed time: 2 ms.
24/11/24 16:51:45 INFO Executor: Finished task 0.0 in stage 9.0 (TID 26). 1901 bytes result sent to driver
24/11/24 16:51:45 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 26) in 16 ms on host.docker.internal (executor driver) (1/2)
24/11/24 16:51:45 INFO FileOutputCommitter: Saved output of task 'attempt_202411241651456558149428303465042_0034_m_000001_0' to file:/C:/Users/tommi/projects/PDI/download-lab-spark-peopleinyear/peopleinyear-spark/peopleinyear.spark_output/as-rdd/_temporary/0/task_202411241651456558149428303465042_0034_m_000001
24/11/24 16:51:45 INFO SparkHadoopMapRedUtil: attempt_202411241651456558149428303465042_0034_m_000001_0: Committed. Elapsed time: 2 ms.
24/11/24 16:51:45 INFO Executor: Finished task 1.0 in stage 9.0 (TID 25). 1944 bytes result sent to driver
24/11/24 16:51:45 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 25) in 24 ms on host.docker.internal (executor driver) (2/2)
24/11/24 16:51:45 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
24/11/24 16:51:45 INFO DAGScheduler: ResultStage 9 (runJob at SparkHadoopWriter.scala:83) finished in 0,036 s
24/11/24 16:51:45 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
24/11/24 16:51:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
24/11/24 16:51:45 INFO DAGScheduler: Job 6 finished: runJob at SparkHadoopWriter.scala:83, took 0,208252 s
24/11/24 16:51:45 INFO SparkHadoopWriter: Start to commit write Job job_202411241651456558149428303465042_0034.
24/11/24 16:51:45 INFO SparkHadoopWriter: Write Job job_202411241651456558149428303465042_0034 committed. Elapsed time: 12 ms.
24/11/24 16:51:45 INFO SparkContext: Invoking stop() from shutdown hook
24/11/24 16:51:45 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/11/24 16:51:45 INFO SparkUI: Stopped Spark web UI at http://host.docker.internal:4040
24/11/24 16:51:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/11/24 16:51:45 INFO MemoryStore: MemoryStore cleared
24/11/24 16:51:45 INFO BlockManager: BlockManager stopped
24/11/24 16:51:45 INFO BlockManagerMaster: BlockManagerMaster stopped
24/11/24 16:51:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/11/24 16:51:45 INFO SparkContext: Successfully stopped SparkContext
24/11/24 16:51:45 INFO ShutdownHookManager: Shutdown hook called
24/11/24 16:51:45 INFO ShutdownHookManager: Deleting directory C:\Users\tommi\AppData\Local\Temp\spark-9c90343e-9fb8-4cba-a3f3-98e32d8d55a2

BUILD SUCCESSFUL in 9s
2 actionable tasks: 1 executed, 1 up-to-date